{{- if .Values.ollama.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ai-homelab.fullname" . }}-ollama
  labels:
    app.kubernetes.io/name: {{ include "ai-homelab.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/component: ollama
spec:
  replicas: {{ .Values.ollama.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "ai-homelab.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
      app.kubernetes.io/component: ollama
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "ai-homelab.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
        app.kubernetes.io/component: ollama
    spec:
      initContainers:
        - name: model-sync
          image: "{{ .Values.ollama.image.repository }}:{{ .Values.ollama.image.tag }}"
          imagePullPolicy: {{ .Values.ollama.image.pullPolicy }}
          command: ["/bin/bash", "-c", "ollama serve & sleep 10 && /scripts/manage_models.sh"]
          env:
            - name: OLLAMA_MODELS
              value: "{{ join "," .Values.ollama.models }}"
          volumeMounts:
          {{- if .Values.ollama.persistence }}
          {{- if .Values.ollama.persistence.enabled }}
            - name: data
              mountPath: /root/.ollama
          {{- end }}
          {{- end }}
            - name: scripts
              mountPath: /scripts
              readOnly: true
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 512Mi
      containers:
        - name: ollama
          image: "{{ .Values.ollama.image.repository }}:{{ .Values.ollama.image.tag }}"
          imagePullPolicy: {{ .Values.ollama.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          {{- if .Values.ollama.persistence }}
          {{- if .Values.ollama.persistence.enabled }}
          volumeMounts:
            - name: data
              mountPath: /root/.ollama
          {{- end }}
          {{- end }}
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: {{ .Values.ollama.healthChecks.liveness.initialDelaySeconds }}
            periodSeconds: {{ .Values.ollama.healthChecks.liveness.periodSeconds }}
            timeoutSeconds: {{ .Values.ollama.healthChecks.liveness.timeoutSeconds }}
            failureThreshold: {{ .Values.ollama.healthChecks.liveness.failureThreshold }}
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: {{ .Values.ollama.healthChecks.readiness.initialDelaySeconds }}
            periodSeconds: {{ .Values.ollama.healthChecks.readiness.periodSeconds }}
            timeoutSeconds: {{ .Values.ollama.healthChecks.readiness.timeoutSeconds }}
            failureThreshold: {{ .Values.ollama.healthChecks.readiness.failureThreshold }}
          resources:
            {{- toYaml .Values.ollama.resources | nindent 12 }}
      volumes:
        - name: scripts
          configMap:
            name: {{ include "ai-homelab.fullname" . }}-ollama-scripts
            defaultMode: 0755
      {{- if .Values.ollama.persistence }}
      {{- if .Values.ollama.persistence.enabled }}
        - name: data
          persistentVolumeClaim:
            claimName: {{ include "ai-homelab.fullname" . }}-ollama-pvc
      {{- end }}
      {{- end }}
{{- end }}