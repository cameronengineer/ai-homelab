# Default values for ai-homelab.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Global configuration
globalConfig:
  imagePullPolicy: IfNotPresent
  nodeSelector: {}
  affinity: {}
  tolerations: []

# LiteLLM configuration
# EXPERIMENTAL
litellm:
  enabled: false
  image:
    repository: ghcr.io/berriai/litellm
    tag: main-latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 4000
    metricsPort: 9090
  resources: {}
  persistence:
    enabled: false
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 8Gi
  healthChecks:
    liveness:
      initialDelaySeconds: 40
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
    readiness:
      initialDelaySeconds: 5
      periodSeconds: 10
  storeModelInDB: true
  masterKey: "sk-litellm-master-key-change-me-in-production"

# PostgreSQL subchart configuration
# EXPERIMENTAL
postgresql:
  enabled: false
  auth:
    postgresPassword: dbpassword9090
    database: litellm
    username: llmproxy
    password: dbpassword9090
  service:
    port: 5432
  persistence:
    enabled: true
    size: 8Gi
  nameOverride: "ai-homelab-litellm-postgresql"

# Open WebUI configuration
openWebUI:
  enabled: true
  replicaCount: 1
  image:
    repository: ghcr.io/open-webui/open-webui
    tag: main
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8080
  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: true
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 5Gi
  environment:
    webuiSecretKey: "webui-secret-key-change-me"
  healthChecks:
    liveness:
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readiness:
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3

# Ollama configuration
ollama:
  enabled: true
  replicaCount: 1
  image:
    repository: ollama/ollama
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 11434
    # DNS name configuration for service discovery
    dns:
      # Use full DNS name with namespace and cluster domain
      useFQDN: false
      # Custom namespace (defaults to .Release.Namespace)
      namespace: ""
      # Custom cluster domain (defaults to cluster.local)
      clusterDomain: "cluster.local"
  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 1000m
      memory: 2Gi
  persistence:
    enabled: true
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 10Gi
  healthChecks:
    liveness:
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
    readiness:
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
  models:
    - llama3.2:1b
    - deepseek-r1:1.5b

# Ingress configuration
ingress:
  enabled: true
  host: ai-homelab.local
  ingressClassName: nginx
  annotations: {}
  tls: false
  tlsSecret: ai-homelab-tls
